{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Online Amazon Reviews using Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Question: How we can analyze a large number of text documents, online product reviews, etc. using NLP?\n",
    "\n",
    "An example on Amazon review data:\n",
    "Ratings alone do not give a complete picture of the products we wish to purchase. A further possibility provides reviews of online products which are a great source of information for consumers. From the seller's point of view, online reviews can be used to gauge the consumer's feedback on the products or services they are selling. However, since these online reviews are quite often overwhelming in terms of numbers and information, we need an intelligent system, that will help for both the consumers and the sellers. This system will serve two purposes:\n",
    "\n",
    "1. Enable consumers to quickly extract the key topics covered by the reviews without having to go through all of them\n",
    "2. Help the sellers get consumer feedback in the form of topics, extacted from the consumer reviews\n",
    "\n",
    "To solve this problem, we will use the concept of Topic Modeling using Latent Dirichlet Allocation (LDA) on Amazon review data. You can download it from this website: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Topic Modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is one of the most popular NLP techniques with several real-world applications such as dimensionality reduction, text summarization, recommendation engine, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we should use Topic Modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling try to automatically identify useful topics present in a text object like document and to derive hidden patterns exhibited by a called text corpus. Topic Modeling can be used for multiple purposes, including:\n",
    "\n",
    "- Document clustering\n",
    "- Organizing large blocks of textual data\n",
    "- Information retrieval from unstructured text\n",
    "- Feature selection\n",
    "\n",
    "Our aim here is to extract a certain useful number of groups of important words from the reviews. These groups of words are basically the topics which would help in ascertaining what the consumers are actually talking about in the reviews. The purpose of this notebook is to demonstrate the application of LDA on a raw, crowd-generated text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dimitriwilhelm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "from textblob import Word\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datapreprocessing as dp\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# libraries for visualization\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1N4O8VOJZTDVB</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>Annette Yancey</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Loves the song, so he really couldn't wait to ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Really cute</td>\n",
       "      <td>1383350400</td>\n",
       "      <td>11 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2HQWU6HUKIEC7</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>Audiobook lover \"Kathy\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Oh, how my little grandson loves this app. He'...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2-year-old loves it</td>\n",
       "      <td>1323043200</td>\n",
       "      <td>12 5, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1SXASF6GYG96I</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>Barbara Gibbs</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I found this at a perfect time since my daught...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fun game</td>\n",
       "      <td>1337558400</td>\n",
       "      <td>05 21, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2B54P9ZDYH167</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>Brooke Greenstreet \"Babylove\"</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>My 1 year old goes back to this game over and ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We love our Monkeys!</td>\n",
       "      <td>1354752000</td>\n",
       "      <td>12 6, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFOFZDTX5UC6D</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>C. Galindo</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>There are three different versions of the song...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is my granddaughters favorite app on my K...</td>\n",
       "      <td>1391212800</td>\n",
       "      <td>02 1, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                   reviewerName helpful  \\\n",
       "0  A1N4O8VOJZTDVB  B004A9SDD8                 Annette Yancey  [1, 1]   \n",
       "1  A2HQWU6HUKIEC7  B004A9SDD8        Audiobook lover \"Kathy\"  [0, 0]   \n",
       "2  A1SXASF6GYG96I  B004A9SDD8                  Barbara Gibbs  [0, 0]   \n",
       "3  A2B54P9ZDYH167  B004A9SDD8  Brooke Greenstreet \"Babylove\"  [3, 4]   \n",
       "4   AFOFZDTX5UC6D  B004A9SDD8                     C. Galindo  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Loves the song, so he really couldn't wait to ...      3.0   \n",
       "1  Oh, how my little grandson loves this app. He'...      5.0   \n",
       "2  I found this at a perfect time since my daught...      5.0   \n",
       "3  My 1 year old goes back to this game over and ...      5.0   \n",
       "4  There are three different versions of the song...      5.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                        Really cute      1383350400   \n",
       "1                                2-year-old loves it      1323043200   \n",
       "2                                           Fun game      1337558400   \n",
       "3                               We love our Monkeys!      1354752000   \n",
       "4  This is my granddaughters favorite app on my K...      1391212800   \n",
       "\n",
       "    reviewTime  \n",
       "0   11 2, 2013  \n",
       "1   12 5, 2011  \n",
       "2  05 21, 2012  \n",
       "3   12 6, 2012  \n",
       "4   02 1, 2014  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Apps = dp.getDF('Apps_for_Android_5.json')\n",
    "df_Apps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains the following columns\n",
    "\n",
    "- reviewerID\n",
    "- asin\n",
    "- reviewerName\n",
    "- helpful\n",
    "- reviewText\n",
    "- overall\n",
    "- summary\n",
    "- unixReviewTime\n",
    "- reviewTime\n",
    "\n",
    "For our analysis, we create a new dataframe with the reviews column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.DataFrame(df_Apps.reviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot most frequent terms\n",
    "def freq_words(x, terms=30):\n",
    "    all_words = \" \".join([word for word in x])\n",
    "    all_words = all_words.split()\n",
    "    \n",
    "    fdist = FreqDist(all_words)\n",
    "    print(fdist.key())\n",
    "    words_df = pd.DataFrame({'word': list(fdist.key()), 'count': list(fdist.values())})\n",
    "    \n",
    "    # selecting top 10 frequent words\n",
    "    d = words_df.nlargest(columns=\"count\", n = terms)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.barplot(x=\"word\", y = \"count\", data = d)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean our data\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # Lower case\n",
    "    # Transform our review into lower case. This avoids having multiple copies of the same words\n",
    "    data['reviewText'] = data['reviewText'].apply(\n",
    "        lambda x: \" \".join( x.lower() for x in x.split() )\n",
    "    )\n",
    "    \n",
    "    # Removing Punctuation, Numbers and Special Characters\n",
    "    # It does not add any extra information while treating text data. Therefore it will help us reduce the size of the data\n",
    "    data['reviewText'] = data['reviewText'].str.replace('[^a-zA-Z#]',' ')\n",
    "    \n",
    "    # Removal of Stop Words, i.e. we just removed commonly occurring words in a genearl sense\n",
    "    # Stop Words should be removed from the text data. We use for this predefined libraries from nltk\n",
    "    data['reviewText'] = data['reviewText'].apply(\n",
    "        lambda x: \" \".join( x for x in x.split() if x not in stop)\n",
    "    )\n",
    "    \n",
    "    # Removing commonly occurring words from our text data\n",
    "    # Let's check the 10 most frequently occuring words in our text data\n",
    "    freq = pd.Series(\" \".join( data['reviewText'] ).split()).value_counts()[:1]\n",
    "    # Let's remove these words as their presence will not of any use in classification of our text data\n",
    "    freq = list(freq.index)\n",
    "    data['reviewText'] = data['reviewText'].apply(\n",
    "        lambda x: \" \".join( x for x in x.split() if x not in freq)\n",
    "    )\n",
    "    \n",
    "    # Remove rare words\n",
    "    # Let's check the 10 rarely occurring words in our text data\n",
    "    #freq_1 = pd.Series(\" \".join( data['reviewText'] ).split()).value_counts()[:-1]\n",
    "    # Let's remove these words as their presence will not of any use in classification of our text data\n",
    "    #freq_1 = list(freq.index)\n",
    "    #data['reviewText'] = data['reviewText'].apply(\n",
    "    #    lambda x: \" \".join(x for x in x.split() if x not in freq_1)\n",
    "    #)\n",
    "    \n",
    "    # Stemming, i.e. we're removing suffices, like \"ing\", \"ly\", etc. by a simple rule-based approach.\n",
    "    # For this purpose, we will use PorterStemmer from the NLTK library\n",
    "    #st = PorterStemmer()\n",
    "    #data['reviewText'] = data['reviewText'].apply(\n",
    "    #    lambda x: \" \".join([ st.stem(word) for word in x.split() ])\n",
    "    #)\n",
    "   \n",
    "    # Lemmatization\n",
    "    # Lemmatization is more effective that stemming because it converts the word into its root word, \n",
    "    # rather than just stripping the suffices. We usually prefer using lemmatiziation over stemming.\n",
    "    data['reviewText'] = data['reviewText'].apply(\n",
    "        lambda x: \" \".join([ Word(word).lemmatize() for word in x.split() ])\n",
    "    )\n",
    "    \n",
    "    # Remove short words (Length < 3)\n",
    "    data['reviewText'] = data['reviewText'].apply(\n",
    "        lambda x: \" \".join([w for w in x.split() if len(w) > 3])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(df_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FreqDist' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6e5d5ddfc4a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfreq_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-a53dac4bd4e4>\u001b[0m in \u001b[0;36mfreq_words\u001b[0;34m(x, terms)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwords_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FreqDist' object has no attribute 'key'"
     ]
    }
   ],
   "source": [
    "freq_words(df_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating the term dictionary of our corpus, where every unique term is assigned an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.reviewText = df_review.reviewText.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [love, song, really, wait, play, little, inter...\n",
       "1    [little, grandson, love, always, asking, monke...\n",
       "2    [found, perfect, time, since, daughter, favori...\n",
       "3    [year, back, simple, easy, toddler, even, caug...\n",
       "4    [three, different, version, song, keep, occupi...\n",
       "5    [cute, great, little, love, think, funny, kick...\n",
       "6    [watch, great, grandson, week, hard, keep, mon...\n",
       "7    [wild, crazy, little, love, singing, song, fiv...\n",
       "8    [love, love, love, going, different, apps, cam...\n",
       "9    [cute, alot, item, move, would, awesome, said,...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.reviewText[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df_review.reviewText[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the list of reviews into a Document Term Matrix using the dictionary prepared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in df_review.reviewText[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LDA model\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix, id2word = dictionary, num_topics=5, random_state=1, chunksize=1000, passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it. We print out the topics that our LDA model has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.054*\"little\" + 0.037*\"year\" + 0.020*\"singing\" + 0.020*\"five\" + 0.020*\"easy\" + 0.020*\"crazy\" + 0.020*\"country\" + 0.020*\"full\" + 0.020*\"included\" + 0.020*\"player\"'),\n",
       " (1,\n",
       "  '0.034*\"monkey\" + 0.023*\"keep\" + 0.023*\"occupied\" + 0.023*\"click\" + 0.023*\"light\" + 0.023*\"ring\" + 0.023*\"great\" + 0.014*\"song\" + 0.013*\"going\" + 0.013*\"toddler\"'),\n",
       " (2,\n",
       "  '0.031*\"cute\" + 0.031*\"item\" + 0.031*\"different\" + 0.031*\"move\" + 0.031*\"moved\" + 0.031*\"alot\" + 0.031*\"said\" + 0.031*\"awesome\" + 0.031*\"would\" + 0.031*\"voice\"'),\n",
       " (3,\n",
       "  '0.057*\"love\" + 0.057*\"little\" + 0.055*\"song\" + 0.046*\"play\" + 0.024*\"really\" + 0.024*\"different\" + 0.024*\"cute\" + 0.013*\"operate\" + 0.013*\"variety\" + 0.013*\"highly\"'),\n",
       " (4,\n",
       "  '0.046*\"monkey\" + 0.031*\"love\" + 0.031*\"grandson\" + 0.031*\"little\" + 0.017*\"great\" + 0.017*\"long\" + 0.017*\"thing\" + 0.017*\"five\" + 0.017*\"worth\" + 0.017*\"well\"')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "#pyLDAvis.enable_notebook()\n",
    "#vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "#ivs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval saves us from the labor of going through product reviews one by one. It gives us a fair idea of what other consumers are talking about the product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Methods to Leverage Online Reviews\n",
    "\n",
    "Apart from Topic Modeling, there are many other methods using NLP as well which are used for analyzing and understanding online reviews. Some ideas:\n",
    "\n",
    "- Text Summarization: Summarize the reviews into a paragraph or a few bullet points\n",
    "- Entity Recognition: Extract entities from the reviews and identify which products are most popular (or unpopular) among the consumers\n",
    "- Identify Emerging Trends: Based on the Timestamp of the reviews, new and emerging topics or entities can be identified. It would be enable us to figure out which products are becoming popular and which are losing their grip on the market\n",
    "- Sentiment Analysis: It tells us whether the reviews are positive, netural or negative. For sellers/retailers, understanding the sentiment of the reviews can be helpful in improving their products and services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
